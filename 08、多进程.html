<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>八、多进程 - js node</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.6.1, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="./images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="./css/style.min.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href="index.html" target="_blank" class="custom-link">js node</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="index.html">
<a href="index.html">Welcome to MkDocs</a>
<li class="chapter" data-path="01%E3%80%81html.html">
<a href="01%E3%80%81html.html">一、HTML</a>
<li class="chapter" data-path="02%E3%80%81CSS%E5%B1%82%E5%8F%A0%E6%A0%B7%E5%BC%8F%E8%A1%A8.html">
<a href="02%E3%80%81CSS%E5%B1%82%E5%8F%A0%E6%A0%B7%E5%BC%8F%E8%A1%A8.html">二、CSS层叠样式表</a>
<li class="chapter" data-path="03%E3%80%81%E6%AD%A3%E5%88%99.html">
<a href="03%E3%80%81%E6%AD%A3%E5%88%99.html">三、正则</a>
<li class="chapter" data-path="04%E3%80%81BS4%E8%A7%A3%E6%9E%90%E5%AE%8C%E6%95%B4.html">
<a href="04%E3%80%81BS4%E8%A7%A3%E6%9E%90%E5%AE%8C%E6%95%B4.html">四、beautifulsoup</a>
<li class="chapter" data-path="05%E3%80%81xpath.html">
<a href="05%E3%80%81xpath.html">五、xpath</a>
<li class="chapter" data-path="06%E3%80%81%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E4%B8%8Eurllib%26requests.html">
<a href="06%E3%80%81%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E4%B8%8Eurllib%26requests.html">六、爬虫入门</a>
<li class="chapter" data-path="07%E3%80%81urllib%E4%B8%8Erequests.html">
<a href="07%E3%80%81urllib%E4%B8%8Erequests.html">七、urllib与requests</a>
<li class="chapter active" data-path="08%E3%80%81%E5%A4%9A%E8%BF%9B%E7%A8%8B.html">
<a href="08%E3%80%81%E5%A4%9A%E8%BF%9B%E7%A8%8B.html">八、多进程</a>
<li class="chapter" data-path="09%E3%80%81%E7%BA%BF%E7%A8%8B.html">
<a href="09%E3%80%81%E7%BA%BF%E7%A8%8B.html">九、线程</a>
<li class="chapter" data-path="10%E3%80%81%E5%8D%8F%E7%A8%8B.html">
<a href="10%E3%80%81%E5%8D%8F%E7%A8%8B.html">十、携程</a>
<li class="chapter" data-path="11%E3%80%81selenium.html">
<a href="11%E3%80%81selenium.html">十一、selenium</a>
<li class="chapter" data-path="12%E3%80%81MySQL%E6%95%B0%E6%8D%AE%E5%BA%93.html">
<a href="12%E3%80%81MySQL%E6%95%B0%E6%8D%AE%E5%BA%93.html">十二、MySQL数据库</a>
<li class="chapter" data-path="13%E3%80%81Mongodb.html">
<a href="13%E3%80%81Mongodb.html">十三、Mongodb</a>
<li class="chapter" data-path="14%E3%80%81redis.html">
<a href="14%E3%80%81redis.html">十四、Redis数据库</a>
<li class="chapter" data-path="15%E3%80%81%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.html">
<a href="15%E3%80%81%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.html">十五、面向对象</a>
<li class="chapter" data-path="16-Scrapy01-%E6%A1%86%E6%9E%B6%E5%88%9D%E8%AE%A4%E8%AF%86.html">
<a href="16-Scrapy01-%E6%A1%86%E6%9E%B6%E5%88%9D%E8%AE%A4%E8%AF%86.html">十六、Scrapy框架初认识</a>
<li class="chapter" data-path="16-Scrapy02%E6%B7%B1%E5%85%A5%E4%BD%BF%E7%94%A8-%E5%AD%98%E5%82%A8.html">
<a href="16-Scrapy02%E6%B7%B1%E5%85%A5%E4%BD%BF%E7%94%A8-%E5%AD%98%E5%82%A8.html">十六、Scrapy深入使用-存储</a>
<li class="chapter" data-path="16-Scrapy03-%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%E4%BB%A5%E5%8F%8A%E5%88%86%E9%A1%B5.html">
<a href="16-Scrapy03-%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%E4%BB%A5%E5%8F%8A%E5%88%86%E9%A1%B5.html">十六、scrapy模拟登陆&amp;分页</a>
<li class="chapter" data-path="16-Scrapy04-%E4%B8%AD%E9%97%B4%E4%BB%B6.html">
<a href="16-Scrapy04-%E4%B8%AD%E9%97%B4%E4%BB%B6.html">十六、Scrapy中间件</a>
<li class="chapter" data-path="16-Scrapy05-%E5%88%86%E9%A1%B5%E6%8A%93%E5%8F%96.html">
<a href="16-Scrapy05-%E5%88%86%E9%A1%B5%E6%8A%93%E5%8F%96.html">十六、scrapy的crawlspider爬虫</a>
<li class="chapter" data-path="16-Scrapy06-scrapy_redis.html">
<a href="16-Scrapy06-scrapy_redis.html">十六、scrapy_redis</a>
<li class="chapter" data-path="17%E3%80%81js%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html">
<a href="17%E3%80%81js%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html">十七、js数据类型</a>
<li class="chapter" data-path="18%E3%80%81%E8%BF%90%E7%AE%97%E7%AC%A6%E4%B8%8E%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6.html">
<a href="18%E3%80%81%E8%BF%90%E7%AE%97%E7%AC%A6%E4%B8%8E%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6.html">十八、js运算符与流程控制</a>
<li class="chapter" data-path="19%E3%80%81js%E6%95%B0%E7%BB%84.html">
<a href="19%E3%80%81js%E6%95%B0%E7%BB%84.html">十九、js数组</a>
<li class="chapter" data-path="20%E3%80%81js%E5%AD%97%E7%AC%A6%E4%B8%B2.html">
<a href="20%E3%80%81js%E5%AD%97%E7%AC%A6%E4%B8%B2.html">二十、js字符串</a>
<li class="chapter" data-path="21%E3%80%81js%E5%AF%B9%E8%B1%A1%E5%92%8C%E6%97%B6%E9%97%B4.html">
<a href="21%E3%80%81js%E5%AF%B9%E8%B1%A1%E5%92%8C%E6%97%B6%E9%97%B4.html">二十一、js对象与时间</a>
<li class="chapter" data-path="22%E3%80%81%E5%87%BD%E6%95%B0%E7%9A%84%E5%AE%9A%E4%B9%89.html">
<a href="22%E3%80%81%E5%87%BD%E6%95%B0%E7%9A%84%E5%AE%9A%E4%B9%89.html">二十二、js函数</a>
<li class="chapter" data-path="23%E3%80%81js%E8%BF%9B%E9%98%B6.html">
<a href="23%E3%80%81js%E8%BF%9B%E9%98%B6.html">二十三、Javascript进阶</a>
<li class="chapter" data-path="24%E3%80%81BOM%E6%93%8D%E4%BD%9C.html">
<a href="24%E3%80%81BOM%E6%93%8D%E4%BD%9C.html">二十四、浏览器对象模型BOM</a>
<li class="chapter" data-path="25%E3%80%81DOM%E6%93%8D%E4%BD%9C.html">
<a href="25%E3%80%81DOM%E6%93%8D%E4%BD%9C.html">二十五、DOM操作</a>
<li class="chapter" data-path="26%E3%80%81jQuery%E6%93%8D%E4%BD%9C.html">
<a href="26%E3%80%81jQuery%E6%93%8D%E4%BD%9C.html">二十六、jQuery</a>
<li class="chapter" data-path="27%E3%80%81%E9%80%86%E5%90%9101.html">
<a href="27%E3%80%81%E9%80%86%E5%90%9101.html">二十七、JS逆向01</a>
<li class="chapter" data-path="28%E3%80%81%E9%80%86%E5%90%9102.html">
<a href="28%E3%80%81%E9%80%86%E5%90%9102.html">二十八、逆向02</a>
<li class="chapter" data-path="29%E3%80%81%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F.html">
<a href="29%E3%80%81%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F.html">二十九、微信小程序逆向开发</a>
<li class="chapter" data-path="30%E3%80%81%E7%BD%91%E6%98%93%E6%BB%91%E5%9D%97.html">
<a href="30%E3%80%81%E7%BD%91%E6%98%93%E6%BB%91%E5%9D%97.html">三十、网易易盾</a>
<li class="chapter" data-path="31%E3%80%81rpc.html">
<a href="31%E3%80%81rpc.html">三十一、RPC</a>
<li class="chapter" data-path="32%E3%80%81TLS%E6%8C%87%E7%BA%B9%E7%BB%95%E8%BF%87.html">
<a href="32%E3%80%81TLS%E6%8C%87%E7%BA%B9%E7%BB%95%E8%BF%87.html">三十二、TLS指纹绕过</a>
<li class="chapter" data-path="33%E3%80%81%E9%AB%98%E7%BA%A7%E9%80%86%E5%90%91.html">
<a href="33%E3%80%81%E9%AB%98%E7%BA%A7%E9%80%86%E5%90%91.html">三十三、高级逆向</a>
<li class="chapter" data-path="34%E3%80%81%E9%AB%98%E7%BA%A7%E9%80%86%E5%90%91.html">
<a href="34%E3%80%81%E9%AB%98%E7%BA%A7%E9%80%86%E5%90%91.html">三十四、高级逆向</a>
<li class="chapter" data-path="%E9%80%86%E5%90%91%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E7%AC%94%E8%AE%B0.html">
<a href="%E9%80%86%E5%90%91%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E7%AC%94%E8%AE%B0.html">逆向实战案例笔记</a>
<li class="header">Pyexecjs与npm配置</li>

<li>
<a href="pyexecjs%E4%B8%8Enpm%E9%85%8D%E7%BD%AE/execjs%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8.html" class="">Execjs介绍以及安装和使用</a>
</li>

<li>
<a href="pyexecjs%E4%B8%8Enpm%E9%85%8D%E7%BD%AE/%E4%B8%80%E6%AC%A1%E6%80%A7%E8%A7%A3%E5%86%B3%E6%8E%89npm%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98.html" class="">更换npm为国内镜像</a>
</li>

<li class="header">补环境</li>

<li>
<a href="%E8%A1%A5%E7%8E%AF%E5%A2%83/1%E3%80%81%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%8E%E4%BA%8B%E4%BB%B6.html" class="">补环境</a>
</li>

<li>
<a href="%E8%A1%A5%E7%8E%AF%E5%A2%83/2%E3%80%81Proxy%E4%BB%A3%E7%90%86%E5%99%A8.html" class="">Proxy代理</a>
</li>

<li>
<a href="%E8%A1%A5%E7%8E%AF%E5%A2%83/3%E3%80%81vm2%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83.html" class="">3、vm2运行环境</a>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h1 id="_1">八、多进程</h1>
<h2 id="_2">一、多任务原理</h2>
<ul>
<li>概念</li>
</ul>
<p>现代操作系统比如Mac OS X，UNIX，Linux，Windows等，都是支持“多任务”的操作系统</p>
<ul>
<li>什么叫多任务？</li>
</ul>
<p>就是操作系统可以同时运行多个任务</p>
<ul>
<li>单核CPU实现多任务原理</li>
</ul>
<p>操作系统轮流让各个任务交替执行，QQ执行2us（微秒），切换到微信，在执行2us，再切换到陌陌，执行2us……。表面是看，每个任务反复执行下去，但是CPU调度执行速度太快了，导致我们感觉就像所有任务都在同时执行一样</p>
<p><img alt="截屏2020-01-1314.49.04" src="imgs/08%E3%80%81%E5%A4%9A%E8%BF%9B%E7%A8%8B.assets/%E6%88%AA%E5%B1%8F2020-01-1314.49.04.png" /></p>
<ul>
<li>多核CPU实现多任务原理</li>
</ul>
<p>​ 真正的秉性执行多任务只能在多核CPU上实现，但是由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行</p>
<p><img alt="截屏2020-01-1314.48.20" src="imgs/08%E3%80%81%E5%A4%9A%E8%BF%9B%E7%A8%8B.assets/%E6%88%AA%E5%B1%8F2020-01-1314.48.20.png" /></p>
<ul>
<li>
<p>并发与并行</p>
</li>
<li>
<p>并发</p>
<p>CPU调度执行速度太快了,看上去一起执行，任务数多于CPU核心数</p>
</li>
<li>
<p>并行</p>
<p>真正一起执行，任务数小于等于CPU核心数</p>
</li>
<li>
<p>并发是逻辑上的同时发生，并行更多是侧重于物理上的同时发生。</p>
</li>
<li>
<p>实现多任务的方式</p>
</li>
<li>
<p>多进程模式</p>
<p>启动多个进程，每个进程虽然只有一个线程，但是多个进程可以一起执行多个任务</p>
</li>
<li>
<p>多线程模式</p>
<p>启动一个进程，在一个进程的内部启动多个线程，这样多个线程也可以一起执行多个任务</p>
</li>
<li>
<p>多进程+多线程</p>
<p>启动多个进程，每个进程再启动多个线程</p>
</li>
<li>
<p>协程</p>
</li>
<li>
<p>多进程+协程</p>
</li>
</ul>
<h2 id="_3">二、进程</h2>
<h3 id="1">1、概念</h3>
<ul>
<li>什么是进程？</li>
</ul>
<p>是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。</p>
<ul>
<li>对于操作系统</li>
</ul>
<p>一个任务就是一个进程。比方说打开浏览器就是启动一个浏览器的进程，在打开一个记事本就启动一个记事本进程，如果打开两个记事本就启动两个记事本进程</p>
<h3 id="2">2、使用进程</h3>
<ul>
<li>单进程现象</li>
</ul>
<p>需要等待代码执行完后再执行下一段代码</p>
<p>```python
  import time</p>
<p>def run1():
      while 1:
          print("lucky is a good man")
          time.sleep(1)</p>
<p>def run2():
      while 1:
          print("lucky is a nice man")
          time.sleep(1)</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
      run1()
      # 不会执行run2()函数，只有上面的run1()结束才能执行run2()
      run2()
  ```</p>
<ul>
<li>
<p>启动进程实现多任务</p>
</li>
<li>
<p>multiprocessing模块</p>
<p>跨平台的多进程模块，提供了一个Process类用来示例化一个进程对象</p>
</li>
<li>
<p>Process类</p>
<p>作用：创建进程(子进程)</p>
</li>
<li>
<p>__name__</p>
<p>这是 Windows 上多进程的实现问题。在 Windows 上，子进程会自动 import 启动它的这个文件，而在 import 的时候是会执行这些语句的。如果你这么写的话就会无限递归创建子进程报错。所以必须把创建子进程的部分用那个 if 判断保护起来，import 的时候 <code>__name__</code> 不是 <code>__main__</code> ，就不会递归运行了。</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>target</td>
<td>指定进程执行的任务</td>
</tr>
<tr>
<td>args</td>
<td>给进程函数传递的参数，是一个元组</td>
</tr>
</tbody>
</table>
<p>注意：此时进程被创建，但是不会启动进程执行</p>
</li>
<li>
<p><strong>启动进程实现多任务</strong></p>
<p>from multiprocessing import Process</p>
<p><strong>创建子进程</strong></p>
<p>P = Process(target=run,args=("nice",),name='当前进程名称')</p>
<ul>
<li>
<p>target指定 子进程运行的函数</p>
</li>
<li>
<p>args 指定传递的参数 , 是元组类型</p>
</li>
<li>
<p>启动进程：Process对象.start()</p>
</li>
</ul>
<p><strong>获取进程信息</strong></p>
<ul>
<li>os.getpid()    获取当前进程id号</li>
<li>os.getppid()  获取当前进程的父进程id号</li>
<li>multiprocessing.current_process().name   获取当前进程名称</li>
</ul>
<p><strong>父子进程的先后顺序</strong></p>
<ul>
<li>
<p>默认   父进程的结束不能影响子线程  让父进程等待子进程结束再执行父进程</p>
</li>
<li>
<p>p.join()  阻塞当前进程，直到调用join方法的那个进程执行完，再继续执行当前进程。</p>
</li>
<li>
<p>全局变量在过个进程中不能共享</p>
</li>
</ul>
<p><strong>注意:</strong> 在子线程中修改全局变量时对父进程中的全局变量没有影响</p>
</li>
<li>
<p>示例代码</p>
<p>```python
import time</p>
<p>from multiprocessing import Process</p>
<p>def run1(name):
    while 1:
        print("%s is a good man"%name)
        time.sleep(1)</p>
<p>def run2():
    while 1:
        print("lucky is a nice man")
        time.sleep(1)</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
    # 程序启动时的进程称为主进程(父进程)</p>
<pre><code># 创建进程并启动
p = Process(target=run1, args=("lucky",))
p.start()

# 主进程执行run2()函数
run2()
</code></pre>
<p>```</p>
</li>
<li>
<p>主进程负责调度</p>
</li>
</ul>
<p>主进程主要做的是调度相关的工作，一般不负责具体业务逻辑</p>
<p>```python
  import time
  from multiprocessing import Process</p>
<p>def run1():
      for i in range(7):
          print("lucky is a good man")
          time.sleep(1)</p>
<p>def run2(name, word):
      for i in range(5):
          print("%s is a %s man"%(name, word))
          time.sleep(1)</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
      t1 = time.time()</p>
<pre><code>  # 创建两个进程分别执行run1、run2
  p1 = Process(target=run1)
  p2 = Process(target=run2, args=("lucky", "cool"))

  # 启动两个进程
  p1.start()
  p2.start()

  # 查看耗时
  t2 = time.time()
  print("耗时：%.2f"%(t2-t1))
</code></pre>
<p>```</p>
<ul>
<li>父子进程的先后顺序</li>
</ul>
<p>主进程的结束不能影响子进程，所以可以等待子进程的结束再结束主进程，等待子进程结束，才能继续运行主进程</p>
<p>p.join()  <em>阻塞当前进程，直到调用join方法的那个进程执行完，再继续执行当前进程。</em></p>
<p>```python
  import time
  from multiprocessing import Process</p>
<p>def run1():
      for i in range(7):
          print("lucky is a good man")
          time.sleep(1)</p>
<p>def run2(name, word):
      for i in range(5):
          print("%s is a %s man"%(name, word))
          time.sleep(1)</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
      t1 = time.time()</p>
<pre><code>  p1 = Process(target=run1)
  p2 = Process(target=run2, args=("lucky", "cool"))

  p1.start()
  p2.start()

  # 主进程的结束不能影响子进程，所以可以等待子进程的结束再结束主进程
  # 等待子进程结束，才能继续运行主进程
  p1.join()
  p2.join()

  t2 = time.time()
  print("耗时：%.2f"%(t2-t1))
</code></pre>
<p>```</p>
<h3 id="3">3、全局变量在多个子进程中不能共享</h3>
<p><strong>原因:</strong></p>
<p>​   在创建子进程时对全局变量做了一个备份,父进程中num变量与子线程中的num不是一个变量</p>
<pre><code class="language-python">from multiprocessing import Process
#全局变量在进程中 不能共享
num = 10
def run():
    print(&quot;我是子进程的开始&quot;)
    global num
    num+=1
    print(num)
    print(&quot;我是子进程的结束&quot;)
if __name__==&quot;__main__&quot;:
    p = Process(target=run)
    p.start()
    p.join()

    print(num)
</code></pre>
<p>尝试列表是否能共享</p>
<pre><code class="language-python">from multiprocessing import Process
#全局变量在进程中 不能共享
mylist = []
def run():
    print(&quot;我是子进程的开始&quot;)
    global mylist
    mylist.append(1)
    mylist.append(2)
    mylist.append(3)
    print(&quot;我是子进程的结束&quot;)

if __name__==&quot;__main__&quot;:
    p = Process(target=run)
    p.start()
    p.join()

    print(mylist)
</code></pre>
<h3 id="4">4、启动大量子进程</h3>
<ul>
<li>获取CPU核心数</li>
</ul>
<p>print('CPU number:' + str(multiprocessing.cpu_count()))</p>
<ul>
<li>导入</li>
</ul>
<p>from multiprocesssing  import Pool</p>
<ul>
<li>开启并发数</li>
</ul>
<p>pp = Pool([参数])   #开启并发数  默认是你的核心数</p>
<ul>
<li>创建子进程,并放入进程池管理</li>
</ul>
<p>apply_async为非阻塞模式(并发执行)</p>
<p>pp.apply_async(run,args=(i,))  #args参数 可以为元组 或者是列表[] </p>
<ul>
<li>关闭进程池</li>
</ul>
<p>pp.close()关闭进程池</p>
<ul>
<li>join()</li>
</ul>
<p>在调用join之前必须先调用close,调用close之后就不能再继续添加新的进程了</p>
<p>pp.join()</p>
<p>进程池对象调用join，会等待进程池中所有的子进程结束完毕再去执行父进程</p>
<ul>
<li>实例</li>
</ul>
<p>```python
  # Pool类：进程池类
  from multiprocessing import Pool
  import time
  import random
  import multiprocessing</p>
<p>def run(index):
      print('CPU number:' + str(multiprocessing.cpu_count()))
      print("子进程 %d 启动"%(index))
      t1 = time.time()
      time.sleep(random.random()* 5+2)
      t2 = time.time()
      print("子进程 %d 结束，耗时：%.2f" % (index, t2-t1))</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
      print("启动主进程……")</p>
<pre><code>  # 创建进程池对象
  # 由于pool的默认值为CPU的核心数，假设有4核心，至少需要5个子进程才能看到效果
  # Pool()中的值表示可以同时执行进程的数量
  pool = Pool(2)
  for i in range(1, 7):
      # 创建子进程，并将子进程放到进程池中统一管理
      pool.apply_async(run, args=(i,))

  # 等待子进程结束
  # 关闭进程池：在关闭后就不能再向进程池中添加进程了
  # 进程池对象在调用join之前必须先关闭进程池
  pool.close()
  #pool对象调用join，主进程会等待进程池中的所有子进程结束才会继续执行主进程
  pool.join()

  print("结束主进程……")
</code></pre>
<p>```</p>
<p>get方法：获取进程的返回值</p>
<p>```python
  from multiprocessing import Lock, Pool
  import time</p>
<p>def function(index):
      print('Start process: ', index)
      time.sleep(2)
      print('End process', index)
      return index</p>
<p>if <strong>name</strong> == '<strong>main</strong>':
      pool = Pool(processes=3)
      for i in range(4):
          result = pool.apply_async(function, (i,))
          print(result.get()) #获取每个 子进程的返回值
      print("Started processes")
      pool.close()
      pool.join()
      print("Subprocess done.")
  ```</p>
<p>注意：这样来获取每个进程的返回值 那么就会变成单进程</p>
<h3 id="5map">5、map方法</h3>
<ul>
<li>概述</li>
</ul>
<p>如果你现在有一堆数据要处理，每一项都需要经过一个方法来处理，那么map非常适合</p>
<p>比如现在你有一个数组，包含了所有的URL，而现在已经有了一个方法用来抓取每个URL内容并解析，那么可以直接在map的第一个参数传入方法名，第二个参数传入URL数组。</p>
<ul>
<li>概述</li>
</ul>
<p>```python
  from multiprocessing import Pool
  import requests
  from requests.exceptions import ConnectionError</p>
<p>def scrape(url):
      try:
          print(requests.get(url))
      except ConnectionError:
          print('Error Occured ', url)
      finally:
          print('URL', url, ' Scraped')</p>
<p>if <strong>name</strong> == '<strong>main</strong>':
      pool = Pool(processes=3)
      urls = [
          'https://www.baidu.com',
          'http://www.meituan.com/',
          'http://blog.csdn.net/',
          'http://xxxyxxx.net'
      ]
      pool.map(scrape, urls)
  ```</p>
<p>在这里初始化一个Pool，指定进程数为3，如果不指定，那么会自动根据CPU内核来分配进程数。</p>
<p>然后有一个链接列表，map函数可以遍历每个URL，然后对其分别执行scrape方法。</p>
<h3 id="6">6、单进程与多进程复制文件对比</h3>
<ul>
<li>单进程复制文件</li>
</ul>
<p>```python
  import time</p>
<p>def copy_file(path, toPath):
      with open(path, "rb") as fp1:
          with open(toPath, "wb") as fp2:
              while 1:
                  info = fp1.read(1024)
                  if not info:
                      break
                  else:
                      fp2.write(info)
                      fp2.flush()</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
      t1 = time.time()</p>
<pre><code>  for i in range(1, 5):
      path = r"/Users/lucky/Desktop/file/%d.mp4"%i
      toPath = r"/Users/lucky/Desktop/file2/%d.mp4"%i
      copy_file(path, toPath)

  t2 = time.time()
  print("单进程耗时：%.2f"%(t2-t1))
</code></pre>
<p>```</p>
<ul>
<li>多进程复制文件</li>
</ul>
<p>```python
  import time
  from multiprocessing import Pool
  import os</p>
<p>def copy_file(path, toPath):
      with open(path, "rb") as fp1:
          with open(toPath, "wb") as fp2:
              while 1:
                  info = fp1.read(1024)
                  if not info:
                      break
                  else:
                      fp2.write(info)
                      fp2.flush()</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
      t1 = time.time()
      path = r"/Users/xialigang/Desktop/视频"
      dstPath = r"/Users/xialigang/Desktop/1视频"
      fileList = os.listdir(path)
      pool = Pool()</p>
<pre><code>  for i in fileList:
      newPath1 = os.path.join(path, i)
      newPath2 = os.path.join(dstPath, i)
      pool.apply_async(copy_file, args=(newPath1, newPath2))

  pool.close()
  pool.join()

  t2 = time.time()
  print("耗时：%.2f"%(t2-t1))
</code></pre>
<p>```</p>
<h3 id="7">7、进程间通信</h3>
<ul>
<li>
<p>队列共享</p>
</li>
<li>
<p>导入</p>
<p>from multiprocessing import Queue</p>
</li>
<li>
<p>使用</p>
<p>que = Queue()  #创建队列</p>
<p>que.put(数据)  #压入数据</p>
<p>que.get()           #获取数据</p>
</li>
<li>
<p>队列常用函数</p>
<p>Queue.empty() 如果队列为空，返回True, 反之False</p>
<p>Queue.full() 如果队列满了，返回True,反之False</p>
<p>Queue.get([block[, timeout]]) 获取队列，timeout等待时间</p>
<p>Queue.get_nowait() 相当Queue.get(False)</p>
<p>Queue.put(item) 阻塞式写入队列，timeout等待时间</p>
<p>Queue.put_nowait(item) 相当Queue.put(item, False)</p>
</li>
<li>
<p>特点：先进先出</p>
</li>
<li>
<p>注意：</p>
<p>get方法有两个参数，blocked和timeout，意思为阻塞和超时时间。默认blocked是true，即阻塞式。</p>
<p>当一个队列为空的时候如果再用get取则会阻塞，所以这时候就需要吧blocked设置为false，即非阻塞式，实际上它就会调用get_nowait()方法，此时还需要设置一个超时时间，在这么长的时间内还没有取到队列元素，那就抛出Queue.Empty异常。</p>
<p>当一个队列为满的时候如果再用put放则会阻塞，所以这时候就需要吧blocked设置为false，即非阻塞式，实际上它就会调用put_nowait()方法，此时还需要设置一个超时时间，在这么长的时间内还没有放进去元素，那就抛出Queue.Full异常。</p>
<p>另外队列中常用的方法</p>
</li>
<li>
<p>队列的大小</p>
<p>Queue.qsize() 返回队列的大小 ，不过在 Mac OS 上没法运行。</p>
</li>
</ul>
<p>实例</p>
<p>```python
  import multiprocessing
  queque = multiprocessing.Queue() #创建 队列
  #如果在子进程 和主进程 之间 都压入了数据 那么在主进程 和 子进程 获取的就是 对方的数据
  def fun(myque):
      # print(id(myque)) #获取当前的队列的存储地址  依然是拷贝了一份
      myque.put(['a','b','c']) #在子进程里面压入数据
      # print("子进程获取",myque.get())#获取队列里面的值</p>
<p>if <strong>name</strong>=='<strong>main</strong>':
      # print(id(queque))
      queque.put([1,2,3,4,5]) #将列表压入队列  如果主进程也压入了数据 那么在主进程取的就是在主进程压入的数据 而不是子进程的
      p = multiprocessing.Process(target=fun,args=(queque,))
      p.start()
      p.join()
      print("主进程获取",queque.get())#在主进程进行获取
      print("主进程获取",queque.get())#在主进程进行获取
      # print("主进程获取",queque.get(block=True, timeout=1))#在主进程进行获取</p>
<p>```</p>
<ul>
<li>
<p>字典共享</p>
</li>
<li>
<p>导入</p>
<p>import multiprocess</p>
</li>
<li>
<p>概述</p>
<p>Manager是一个进程间高级通信的方法  支持Python的字典和列表的数据类型</p>
</li>
<li>
<p>创建字典</p>
<p>myDict = multiprocess.Manager().dict()</p>
</li>
</ul>
<p>实例</p>
<p>```python
  import multiprocessing</p>
<p>def fun(mydict):
      # print(mylist)
      mydict['x'] = 'x'
      mydict['y'] = 'y'
      mydict['z'] = 'z'</p>
<p>if <strong>name</strong>=='<strong>main</strong>':
      # Manager是一种较为高级的多进程通信方式，它能支持Python支持的的任何数据结构。
      mydict = multiprocessing.Manager().dict()
      p = multiprocessing.Process(target=fun,args=(mydict,))
      p.start()
      p.join()
      print(mydict)
  ```</p>
<ul>
<li>
<p>列表共享</p>
</li>
<li>
<p>导入</p>
<p>import multiprocess</p>
</li>
<li>
<p>创建列表</p>
<p>myDict = multiprocess.Manager().list()</p>
</li>
</ul>
<p>实例(字典与列表共享)</p>
<p>```python
  import multiprocessing</p>
<p>def fun(List):
      # print(mylist)
      List.append('x')
      List.append('y')
      List.append('z')</p>
<p>if <strong>name</strong>=='<strong>main</strong>':
      # Manager是一种较为高级的多进程通信方式，它能支持Python支持的的任何数据结构。
      List = multiprocessing.Manager().list()
      p = multiprocessing.Process(target=fun,args=(List,))
      p.start()
      p.join()
      print(List)
  ```</p>
<ul>
<li>注意</li>
</ul>
<p>进程名.terminate() 强行终止子进程</p>
<ul>
<li>deamon</li>
</ul>
<p>在这里介绍一个属性，叫做deamon。每个进程程都可以单独设置它的属性，如果设置为True，当父进程结束后，子进程会自动被终止。</p>
<p>进程.daemon = True</p>
<p>设置在start()方法之前</p>
<p><code>python
  import multiprocessing
  import time
  def fun():
      time.sleep(100)
  if __name__=='__main__':
      p = multiprocessing.Process(target=fun)
      p.daemon = True
      p.start()
      print('over')</code></p>
<ul>
<li>进程名.terminate() 强行终止子进程</li>
</ul>
<p><code>Python
  import multiprocessing
  import time
  def fun():
      time.sleep(100)
  if __name__=='__main__':
      p = multiprocessing.Process(target=fun)
      p.start()
      p.terminate()
      p.join()
      print('over')</code></p>
<h3 id="8">8、进程实现生产者消费者</h3>
<p><strong>生产者消费者模型描述：</strong></p>
<p>生产者是指生产数据的任务，消费者是指消费数据的任务。</p>
<p>当生产者的生产能力远大于消费者的消费能力，生产者就需要等消费者消费完才能继续生产新的数据，同理，如果消费者的消费能力远大于生产者的生产能力，消费者就需要等生产者生产完数据才能继续消费，这种等待会造成效率的低下，为了解决这种问题就引入了生产者消费者模型。</p>
<p>生产者/消费者问题可以描述为：两个或者更多的进程（线程）共享同一个缓冲区，其中一个或多个进程（线程）作为“生产者”会不断地向缓冲区中添加数据，另一个或者多个进程（线程）作为“消费者”从缓冲区中取走数据。</p>
<ul>
<li>代码</li>
</ul>
<p>```python
  from multiprocessing import Process
  from multiprocessing import Queue
  import time</p>
<p>def product(q):
      print("启动生产子进程……")
      for data in ["good", "nice", "cool", "handsome"]:
          time.sleep(2)
          print("生产出：%s"%data)
          # 将生产的数据写入队列
          q.put(data)
      print("结束生产子进程……")</p>
<p>def t(q):
      print("启动消费子进程……")
      while 1:
          print("等待生产者生产数据")
          # 获取生产者生产的数据，如果队列中没有数据会阻塞，等待队列中有数据再获取
          value = q.get()
          print("消费者消费了%s数据"%(value))
      print("结束消费子进程……")</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
      q = Queue()</p>
<pre><code>  p1 = Process(target=product, args=(q,))
  p2 = Process(target=customer, args=(q,))

  p1.start()
  p2.start()

  p1.join()
  # p2子进程里面是死循环，无法等待它的结束
  # p2.join()
  # 强制结束子进程
  p2.terminate()

  print("主进程结束")
</code></pre>
<p>```</p>
<h3 id="9">9、案例（抓取斗图）</h3>
<pre><code class="language-python">from multiprocessing import Process,Queue
from concurrent.futures import ThreadPoolExecutor
from lxml import etree
import time
import requests

headers = {
    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36&quot;
}

def get_img_src(url, q):
    &quot;&quot;&quot;
    进程1: 负责提取页面中所有的img的下载地址
    将图片的下载地址通过队列. 传输给另一个进程进行下载
    &quot;&quot;&quot;

    resp = requests.get(url, headers=headers)
    tree = etree.HTML(resp.text)
    srcs = tree.xpath(&quot;//li[@class='list-group-item']//img[@referrerpolicy='no-referrer']/@data-original&quot;)
    for src in srcs:
        q.put(src.strip())
    resp.close()



def download_img(q):
    &quot;&quot;&quot;
        进程2: 将图片的下载地址从队列中提取出来. 进行下载.
   &quot;&quot;&quot;
    with ThreadPoolExecutor(20) as t:
        while 1:
            try:
                s = q.get(timeout=20)
                t.submit(donwload_one, s)
            except Exception as e:
                print(e)
                break

def donwload_one(s):
    # 单纯的下载功能
    resp = requests.get(s, headers=headers)
    file_name = s.split(&quot;/&quot;)[-1]
    # 请提前创建好img文件夹
    with open(f&quot;img/{file_name}&quot;, mode=&quot;wb&quot;) as f:
        f.write(resp.content)
    print(&quot;一张图片下载完毕&quot;, file_name)
    resp.close()

if __name__ == '__main__':
    t1 = time.time()
    q = Queue()  # 两个进程必须使用同一个队列. 否则数据传输不了
    p_list = []
    for i in range(1, 11):
        url = f&quot;https://www.pkdoutu.com/photo/list/?page={i}&quot;
        p = Process(target=get_img_src, args=(url, q))
        p_list.append(p)
    for p in p_list:
        p.start()
    p2 = Process(target=download_img, args=(q,))
    p2.start()
    for p in p_list:
        p.join()
    p2.join()
    print((time.time()-t1)/60)
# 0.49572664896647134
</code></pre>


</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="./js/main.js"></script>
<script src="search/main.js"></script>
<script src="./js/gitbook.min.js"></script>
<script src="./js/theme.min.js"></script>
</body>
</html>